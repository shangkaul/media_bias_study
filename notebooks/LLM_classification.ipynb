{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d85b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263852e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\"id\":\"gen-1750627871-7VwDMe6A8TSxRKFJVEVg\",\"provider\":\"OpenAI\",\"model\":\"openai/gpt-3.5-turbo\",\"object\":\"chat.completion\",\"created\":1750627871,\"choices\":[{\"logprobs\":null,\"finish_reason\":\"stop\",\"native_finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Pong! How can I assist you today?\",\"refusal\":null,\"reasoning\":null}}],\"system_fingerprint\":null,\"usage\":{\"prompt_tokens\":8,\"completion_tokens\":10,\"total_tokens\":18,\"prompt_tokens_details\":{\"cached_tokens\":0},\"completion_tokens_details\":{\"reasoning_tokens\":0}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = \"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\"\n",
    "URL     = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\":  \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\":    \"openai/gpt-3.5-turbo\",\n",
    "    \"messages\": [{\"role\":\"user\", \"content\":\"ping\"}]\n",
    "}\n",
    "\n",
    "resp = requests.post(URL, headers=headers, json=payload)\n",
    "print(resp.status_code, resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed343c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying 200 articles: 100%|██████████| 200/200 [07:43<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report ---\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "             Conflict-related       0.45      0.98      0.62        50\n",
      "Protests and Public Reactions       0.88      0.45      0.60        33\n",
      "         Political Statements       0.21      0.43      0.29        35\n",
      "                   Irrelevant       0.75      0.04      0.07        82\n",
      "\n",
      "                     accuracy                           0.41       200\n",
      "                    macro avg       0.57      0.47      0.39       200\n",
      "                 weighted avg       0.60      0.41      0.33       200\n",
      "\n",
      "Macro F1 score: 0.39295848220815305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ←––––– Your OpenRouter key here ––––→\n",
    "API_KEY = \"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\"\n",
    "URL     = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "MODEL   = \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "# Mapping category names ↔ integer labels\n",
    "label_map = {\n",
    "    \"Conflict-related\": 1,\n",
    "    \"Protests and Public Reactions\": 2,\n",
    "    \"Political Statements\": 3,\n",
    "    \"Irrelevant\": 4\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Load your 200-article test set\n",
    "with open(\"articles_test.json\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "def create_prompt(article):\n",
    "    txt = article[\"title\"]\n",
    "    if article.get(\"description\"):\n",
    "        txt += \"\\n\\n\" + article[\"description\"]\n",
    "    txt += \"\\n\\n\" + article[\"text\"]\n",
    "    return f\"\"\"You are a news classification assistant.\n",
    "\n",
    "Classify the following news article into ONE of these categories:\n",
    "1. Conflict-related\n",
    "2. Political Statements\n",
    "3. Protests and Public Reactions\n",
    "4. Irrelevant\n",
    "\n",
    "Return ONLY the category name (no extra text).\n",
    "\n",
    "Article:\n",
    "{txt}\n",
    "\"\"\"\n",
    "\n",
    "def classify_article(article):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\":    MODEL,\n",
    "        \"messages\": [{\"role\":\"user\", \"content\": create_prompt(article)}],\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "    r = requests.post(URL, headers=headers, json=payload)\n",
    "    if r.status_code != 200:\n",
    "        print(\"Error\", r.status_code, r.text)\n",
    "        return -1\n",
    "    reply = r.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
    "    for cat, idx in label_map.items():\n",
    "        if cat.lower() in reply:\n",
    "            return idx\n",
    "    return -1\n",
    "\n",
    "# Run classification\n",
    "y_true, y_pred = [], []\n",
    "for art in tqdm(articles, desc=\"Classifying 200 articles\"):\n",
    "    y_true.append(art[\"label\"])\n",
    "    y_pred.append(classify_article(art))\n",
    "    time.sleep(1.2)   # to respect rate limits\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[reverse_label_map[i] for i in sorted(reverse_label_map)]\n",
    "))\n",
    "print(\"Macro F1 score:\", f1_score(y_true, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be42f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles processed: 200\n",
      "✅ Successful classifications: 200\n",
      "❌ Errors (returned -1):   0\n"
     ]
    }
   ],
   "source": [
    "# after your run…\n",
    "total = len(y_pred)\n",
    "errors = y_pred.count(-1)\n",
    "success = total - errors\n",
    "\n",
    "print(f\"Total articles processed: {total}\")\n",
    "print(f\"✅ Successful classifications: {success}\")\n",
    "print(f\"❌ Errors (returned -1):   {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m full_text \u001b[38;5;241m=\u001b[39m art[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m art\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m art[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 6.1) Summarize to ~200 tokens\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m summ \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# 6.2) Classify the summary\u001b[39;00m\n\u001b[1;32m     59\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a news classification assistant.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassify this summary into ONE of: Conflict-related, Political Statements,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProtests and Public Reactions, Irrelevant.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msumm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCategory:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:298\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:186\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    191\u001b[0m     ):\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1431\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1425\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         )\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1438\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1437\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1438\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1338\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1337\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1338\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:215\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    213\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 215\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/generation/utils.py:2412\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   2411\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 2412\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/generation/utils.py:854\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    852\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    853\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 854\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1015\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m-> 1015\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1018\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:106\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length, position_ids)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30cd4e59",
   "metadata": {},
   "source": [
    "## Baseline BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a5b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Validation Report:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "             Conflict-related       0.67      0.60      0.63        10\n",
      "Protests and Public Reactions       0.50      0.14      0.22         7\n",
      "         Political Statements       0.00      0.00      0.00         7\n",
      "                   Irrelevant       0.48      0.88      0.62        16\n",
      "\n",
      "                     accuracy                           0.53        40\n",
      "                    macro avg       0.41      0.40      0.37        40\n",
      "                 weighted avg       0.45      0.53      0.45        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid1/MSCs/AY2425/skaul/miniconda3/envs/scraper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/raid1/MSCs/AY2425/skaul/miniconda3/envs/scraper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/raid1/MSCs/AY2425/skaul/miniconda3/envs/scraper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Validation Report:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "             Conflict-related       0.50      1.00      0.67        10\n",
      "Protests and Public Reactions       1.00      0.14      0.25         7\n",
      "         Political Statements       0.67      0.29      0.40         7\n",
      "                   Irrelevant       0.88      0.88      0.88        16\n",
      "\n",
      "                     accuracy                           0.68        40\n",
      "                    macro avg       0.76      0.58      0.55        40\n",
      "                 weighted avg       0.77      0.68      0.63        40\n",
      "\n",
      "\n",
      "Epoch 3 Validation Report:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "             Conflict-related       0.62      1.00      0.77        10\n",
      "Protests and Public Reactions       1.00      0.43      0.60         7\n",
      "         Political Statements       0.57      0.57      0.57         7\n",
      "                   Irrelevant       0.93      0.81      0.87        16\n",
      "\n",
      "                     accuracy                           0.75        40\n",
      "                    macro avg       0.78      0.70      0.70        40\n",
      "                 weighted avg       0.80      0.75      0.74        40\n",
      "\n",
      "Final Macro F1: 0.7018315018315018\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import json\n",
    "\n",
    "# 1) Load your full labeled dataset (must contain 'title', 'text', 'label')\n",
    "with open(\"articles_test.json\") as f:\n",
    "    data = json.load(f)\n",
    "texts  = [d['title'] + \" \" + d['text'] for d in data]\n",
    "labels = [d['label'] - 1 for d in data]  # convert 1–4 → 0–3\n",
    "\n",
    "# 2) Split into train/validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# 3) Tokenizer & Dataset definition\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length)\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset   = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# 4) Model & optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 5) DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# 6) Training loop\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "            labels=batch['labels'].to(device)\n",
    "        )\n",
    "        outputs.loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            out = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device)\n",
    "            )\n",
    "            preds = torch.argmax(out.logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} Validation Report:\")\n",
    "    print(classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        target_names=[\n",
    "            \"Conflict-related\",\n",
    "            \"Protests and Public Reactions\",\n",
    "            \"Political Statements\",\n",
    "            \"Irrelevant\"\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "# Final Macro F1\n",
    "final_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(\"Final Macro F1:\", final_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba8242",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16cdacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Summarize (with fallback to first 200 chars if something goes wrong)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     summ_list \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     summary \u001b[38;5;241m=\u001b[39m summ_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:298\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:186\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    191\u001b[0m     ):\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1431\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1425\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         )\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1438\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1437\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1438\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/base.py:1338\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1337\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1338\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:215\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    213\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 215\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/generation/utils.py:2616\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n\u001b[1;32m   2615\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2616\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2628\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2629\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2635\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2636\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/generation/utils.py:4030\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   4027\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   4028\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m-> 4030\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4032\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   4033\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   4034\u001b[0m     model_outputs,\n\u001b[1;32m   4035\u001b[0m     model_kwargs,\n\u001b[1;32m   4036\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   4037\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1714\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1710\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1711\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1712\u001b[0m         )\n\u001b[0;32m-> 1714\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1734\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1525\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1518\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1519\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1520\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1521\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1522\u001b[0m     )\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1345\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1332\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1333\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         cache_position,\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1345\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1359\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:667\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 667\u001b[0m     hidden_states, cross_attn_weights, past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    676\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraper/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:484\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    480\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_causal \u001b[38;5;129;01mand\u001b[39;00m causal_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# NOTE: SDPA with memory-efficient backend is currently (torch==2.1.2) bugged when using non-contiguous inputs and a custom attn_mask,\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# but we are fine here as `_shape` do call `.contiguous()`. Reference: https://github.com/pytorch/pytorch/issues/112577\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "# 1) Load your articles\n",
    "with open(\"articles_test.json\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "# 2) Summarizer pipeline (CPU)\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# 3) Classifier (BloomZ-3B in 8-bit)\n",
    "model_name = \"bigscience/bloomz-3b\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "classifier = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=16,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "# 4) Label mapping\n",
    "candidate_labels = [\n",
    "    \"Conflict-related\",\n",
    "    \"Political Statements\",\n",
    "    \"Protests and Public Reactions\",\n",
    "    \"Irrelevant\"\n",
    "]\n",
    "label_map = {\n",
    "    \"Conflict-related\":              1,\n",
    "    \"Protests and Public Reactions\": 2,\n",
    "    \"Political Statements\":          3,\n",
    "    \"Irrelevant\":                    4\n",
    "}\n",
    "\n",
    "# 5) Summarize + classify with guards\n",
    "y_true, y_pred = [], []\n",
    "for art in articles:\n",
    "    full_text = art[\"title\"] + \"\\n\\n\" + art.get(\"description\",\"\") + \"\\n\\n\" + art[\"text\"]\n",
    "\n",
    "    # Summarize (with fallback to first 200 chars if something goes wrong)\n",
    "    try:\n",
    "        summ_list = summarizer(full_text, max_length=200, min_length=100, do_sample=False)\n",
    "        summary = summ_list[0][\"summary_text\"]\n",
    "    except Exception:\n",
    "        summary = full_text[:200]\n",
    "\n",
    "    # Classify (with fallback to “Irrelevant” on any error)\n",
    "    prompt = (\n",
    "        \"You are a news classification assistant.\\n\\n\"\n",
    "        \"Classify this summary into ONE of: Conflict-related, Political Statements,\\n\"\n",
    "        \"Protests and Public Reactions, Irrelevant.\\n\\n\"\n",
    "        f\"Summary:\\n{summary}\\n\\nCategory:\"\n",
    "    )\n",
    "    try:\n",
    "        outputs = classifier(prompt)\n",
    "        if outputs and \"generated_text\" in outputs[0]:\n",
    "            out_text = outputs[0][\"generated_text\"]\n",
    "            pred_label = out_text.split(\"Category:\")[-1].strip().split(\"\\n\")[0]\n",
    "        else:\n",
    "            pred_label = \"Irrelevant\"\n",
    "    except Exception:\n",
    "        print(f\"Error classifying article {art['title'][:30]}... - defaulting to Irrelevant\")\n",
    "\n",
    "    y_true.append(art[\"label\"])\n",
    "    y_pred.append(label_map.get(pred_label, 4))  # default to Irrelevant=4\n",
    "\n",
    "# 6) Metrics\n",
    "print(\"Prediction counts:\", Counter(y_pred))\n",
    "print(\"\\n\" + classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=[1,2,3,4],\n",
    "    target_names=candidate_labels\n",
    "))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e70cc",
   "metadata": {},
   "source": [
    "## DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a360ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"model\": \"deepseek/deepseek-r1-0528:free\", \"messages\": [{\"role\": \"user\", \"content\": \"You are a news classification assistant.\\\\n\\\\nClassify into ONE category:\\\\n1. Conflict-related  \\xe2\\x80\\x93 News directly reporting on Israel\\xe2\\x80\\x93Palestine conflict events\\\\n2. Political Statements  \\xe2\\x80\\x93 Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\\\n3. Protests and Public Reactions  \\xe2\\x80\\x93 Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\\\n4. Irrelevant  \\xe2\\x80\\x93 Not related to the conflict in any way\\\\n\\\\nReturn ONLY the category name.\\\\n\\\\nTitle: Ramadan in Gaza: Palestinians fast amid war, devastation and looming famine\\\\n\\\\nContent: On the eve of  Ramadan , Hussein Owda and seven members of his family sat down for suhour \\xe2\\x80\\x94 the meal Muslims eat before fasting from sunrise to sunset. On the table in front of them were just 7 ounces of labneh, or yogurt cheese, and some bread. \\xe2\\x80\\x9cWe didn\\xe2\\x80\\x99t finish it, because we are used to eating small amounts of food,\\xe2\\x80\\x9d Owda, 37, told NBC News   in a telephone interview. The computer engineer, who was displaced to Rafah in southern  Gaza , said he has lost about 65 pounds since the war between Israel and Hamas began on Oct. 7.  Owda, like others NBC News spoke to, said he and his family had been forced to fast for about six months. Now that Ramadan has started, the only difference is that the fast is scheduled. The  ninth and most sacred month of the Islamic calendar , Ramadan is when Muslims believe the first verses of the Quran were revealed to the Prophet Muhammad. Around the world, millions who are able will fast during daylight hours to try to strengthen their connection to God and practice discipline and compassion for the less fortunate. Self-reflection, gratitude and   celebration among community are at its core. In Gaza, the usually joyous season marked by gatherings over traditional food and congregational prayers is unrecognizable. Homes once decorated with lights have been reduced to rubble, and tables once surrounded by families and laden with food are bare. Amid  a worsening humanitarian crisis  in the enclave, where more than 31,000 people have been killed and over 25  have died of starvation , according to Gaza officials, many Muslims are seeking refuge in God and observing the fast as a testament to their unwavering faith during profound hardship. Khaled al-Naji and his family have iftar among the rubble of their destroyed house on the first day of Ramadan in Deir al-Balah on March 11. Ali Jadallah / Anadolu via Getty Images Looming famine and broken traditions On the first day of Ramadan, Salem Sbeta, 48, and his family traditionally eat chicken and molokhia, a stew made of jute leaves. Shopping and preparations for Ramadan would start a month earlier and include decorating the home and buying ingredients for traditional sweets, like qatayef \\xe2\\x80\\x94 sweet stuffed pancakes \\xe2\\x80\\x94 to eat after sunset. \\xe2\\x80\\x9cNormally we\\xe2\\x80\\x99d all be gathered, the whole family would be with me,\\xe2\\x80\\x9d said Sbeta,   who   was displaced from Al Shuja\\xe2\\x80\\x99iyya, a neighborhood of Gaza City, to Rafah. \\xe2\\x80\\x9cWe\\xe2\\x80\\x99d be in the house, feeling safe. We had electricity, cold water, a fridge, juices. We made coffee.\\xe2\\x80\\x9d At the Sbetas\\xe2\\x80\\x99 makeshift home, handmade Ramadan decorations hang from the ceiling, including a paper fanous, a traditional lantern. NBC News This year, handmade Ramadan decorations festoon the makeshift tent shared by nine family members. \\xe2\\x80\\x9cToday, of course, as you can see, there\\xe2\\x80\\x99s no gas. We cook on a fire we make ourselves that burns our hands,\\xe2\\x80\\x9d he said. Infinitely worse than their surroundings are the missing family members: One son was killed in the violence and another one was wounded. \\xe2\\x80\\x9cI used to knock on their doors and say, \\xe2\\x80\\x98Get up, it\\xe2\\x80\\x99s time for suhour!\\xe2\\x80\\x99\\xe2\\x80\\x9d Sbeta\\xe2\\x80\\x99s wife, Sabah, said tearfully, referring to the meal eaten before sunrise. \\xe2\\x80\\x9cI can\\xe2\\x80\\x99t do that anymore.\\xe2\\x80\\x9d The family that remains is trying to celebrate. This year, Salem Sbeta was able to provide molokhia for his family for iftar, or breakfast, on the first day of Ramadan.   It cost him the equivalent of $8 for just over 2 pounds; before the war, the same amount would have cost a little over $1 for the same quantity. Sbeta, a chef by trade, has not been able to work since the war started. The situation is even worse in northern Gaza, where many have no choice but to forage for and cook khobiza, a wild plant. Samiya Abed Jamal, who was displaced to the Jabalia refugee camp, said even this isn\\xe2\\x80\\x99t always an option. \\xe2\\x80\\x9cWe did not eat   suhour, we just drank water and went to bed,\\xe2\\x80\\x9d she said. \\xe2\\x80\\x9cWe do not have bread or flour.\\xe2\\x80\\x9d \\xe2\\x80\\x9cWhat can we do?\\xe2\\x80\\x9d Jamal asked. Muslims are encouraged to eat especially nutritious food during Ramadan, including fresh fruit and vegetables, beans, eggs, dairy and animal protein. But this year, a rich and diverse diet is impossible for a vast majority of those living in Gaza. More than half a million Gaza residents face starvation , according to the United Nations. Meanwhile, less and less food and emergency assistance is getting into the enclave, with the amount of humanitarian aid entering Gaza falling by 50% from January to February, according to UNRWA, the United Nations agency serving Palestinian refugees. Israeli forces have been  accused of opening fire on people waiting for food ,  striking aid distribution sites  and  turning away aid trucks .  The World Food Programme has said  famine is imminent  in northern Gaza. Over 30% of children under the age of 2 currently suffer from acute malnutrition in the area, up from around 16% in January, UNICEF warned on Friday. Ramadan at a soup kitchen Mahmoud Almadhoun ran a cellphone store in Beit Lahia in northern Gaza before the war.   Now the shop lies in ruins, and instead of selling phones, Almadhoun, 32, feeds the hungry at   the Gaza Soup Kitchen, which is funded by a GoFundMe started by his brother who lives in Washington, D.C. In Beit Lahia, northern Gaza, Mahmoud Almadhoun established the Gaza Soup Kitchen, which has been feeding families every day since it began operations in February. Eshak Daour / Gaza Soup Kitchen On the first day of Ramadan, people gathered around the soup kitchen with hopes of securing food for their families. Almadhoun serves around 500 people per day, and crowds begin showing up at the soup kitchen at 11 a.m. to wait for food to be distributed in the evening, he said. \\xe2\\x80\\x9cPeople are in dire need of food in the north. There\\xe2\\x80\\x99s nothing here but khobiza,\\xe2\\x80\\x9d Almadhoun said. With such severe shortages, many in the north of the strip eat just one meal a day, said Juliette Touma, UNRWA\\xe2\\x80\\x99s director of communications. \\xe2\\x80\\x9cIt is very difficult to find the basics, to cook,\\xe2\\x80\\x9d she said. \\xe2\\x80\\x9cThere is no fresh produce, like vegetables and fruit \\xe2\\x80\\x94 dairy products are not really available. So, it\\xe2\\x80\\x99s a very hard and a very, very sad Ramadan for the people of Gaza.\\xe2\\x80\\x9d Products that are available are very expensive and out of reach for many Palestinians, Touma said. The price of eggs has increased tenfold since the war began, and besides, they often aren\\xe2\\x80\\x99t fresh, which has sickened a number of people, she added. But even if they\\xe2\\x80\\x99re lucky enough to have quality   food this Ramadan, most Gaza residents will not be celebrating at home because the war has displaced an estimated 80% of the population and  destroyed 45% of its buildings . A Palestinian man walks atop the rubble of a collapsed building in Rafah, southern Gaza, on Jan. 1. AFP - Getty Images file The war was triggered by Hamas\\xe2\\x80\\x99 Oct. 7 multipronged attack on Israel that killed 1,200 people and resulted in the abduction of some 240 \\xe2\\x80\\x94 around 130 are believed to remain in Gaza. The potential for a cease-fire seems distant as Israeli airstrikes continue in the enclave, with an  expanding military operation into Rafah  appearing  imminent . Moving around the enclave is difficult and dangerous, and visiting family and friends, a hallmark of Ramadan celebrations, is now impossible for many, like Owda. \\xe2\\x80\\x9cThere\\xe2\\x80\\x99s nothing left,\\xe2\\x80\\x9d Owda said. \\xe2\\x80\\x9cMy home is gone, it was destroyed. My parent\\xe2\\x80\\x99s home is also gone, my sister\\xe2\\x80\\x99s home is gone, my brother\\xe2\\x80\\x99s home is gone, my uncle\\xe2\\x80\\x99s home is gone, my grandfather\\xe2\\x80\\x99s home is gone \\xe2\\x80\\x94 there aren\\xe2\\x80\\x99t even any homes left to  visit.\\xe2\\x80\\x9d Owda can\\xe2\\x80\\x99t spend time with his uncle and uncle\\xe2\\x80\\x99s family like he did last year because they were all killed in an airstrike. \\xe2\\x80\\x9cWe don\\xe2\\x80\\x99t even know where they were buried, so I can\\xe2\\x80\\x99t even visit their graves,\\xe2\\x80\\x9d he said. A reliance on God Anyone who can\\xe2\\x80\\x99t take part in the fast in a healthy and safe way is exempt from it \\xe2\\x80\\x94  including those who are sick  or malnourished. However, many Muslim Gazans who say they\\xe2\\x80\\x99ve been hungry for months anyway are observing the fast without access to the quality food and clean water they need out of devotion to God. Sabah Sbeta, 45, is grateful for what she has this Ramadan and plans to fast, leaning heavily on the Islamic concept of   tawakkul, a trust in and reliance on God. \\xe2\\x80\\x9cThank God, lord of all the worlds, for everything. Oh, God, there is no objection to your ruling,\\xe2\\x80\\x9d she said, uttering a prayer that many Muslims say when going through difficult times. Sbeta is not the only Muslim in Gaza who has relied on her faith amid the ongoing war. Worshippers perform the first taraweeh of Ramadan on the rubble of Al-Farouq Mosque in Rafah on March 10. Abed Zagout / Anadolu via Getty Images While most of the enclave\\xe2\\x80\\x99s mosques have been destroyed, believers   gathered on the eve of Ramadan by the ruins of Al-Farouq Mosque in Rafah to pray taraweeh, the congregational Ramadan evening prayers. As the sunset call to prayer is heard across Gaza, families sit down to break their fast   surrounded by memories of what once was. \\xe2\\x80\\x9cWe are doing our best just to survive,\\xe2\\x80\\x9d Owda said. \\xe2\\x80\\x9cWe don\\xe2\\x80\\x99t have the luxury of anything else.\\xe2\\x80\\x9d \\xe2\\x80\\x9cGod is sufficient for me, and he is the best disposer of affairs.\\xe2\\x80\\x9d Mirna Alsharif Mirna Alsharif is a breaking news reporter for NBC News.\"}]}'\n",
      "{'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1750636800000'}, 'provider_name': None}}, 'user_id': 'user_2ysbUVxgqgRyKZF5uPpWKGS2brQ'}\n",
      "b'{\"model\": \"deepseek/deepseek-r1-0528:free\", \"messages\": [{\"role\": \"user\", \"content\": \"You are a news classification assistant.\\\\n\\\\nClassify into ONE category:\\\\n1. Conflict-related  \\xe2\\x80\\x93 News directly reporting on Israel\\xe2\\x80\\x93Palestine conflict events\\\\n2. Political Statements  \\xe2\\x80\\x93 Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\\\n3. Protests and Public Reactions  \\xe2\\x80\\x93 Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\\\n4. Irrelevant  \\xe2\\x80\\x93 Not related to the conflict in any way\\\\n\\\\nReturn ONLY the category name.\\\\n\\\\nTitle: Lakewood shooter \\xe2\\x80\\x98donated money to megachurch\\xe2\\x80\\x99 before attack that left son fighting for life\\\\n\\\\nContent: Lakewood Church shooter Genesse Moreno  reportedly donated money to the Texas megachurch years before she took her seven-year-old son to the religious institution and opened fire inside. On Sunday, the 36-year-old walked into  Joel Osteen\\xe2\\x80\\x99s megachurch  around 1.50pm with her seven-year-old son and armed with an AR-15 rifle.  Inside, she began shooting in the hallway of the building, sending worshippers running for cover. Two off-duty police officers returned fire,  fatally shooting Moreno . Her seven-year-old son was also shot in the head amid the chaos.  Her son was rushed to hospital where he remains in critical condition. Another victim \\xe2\\x80\\x93 a 57-year-old man \\xe2\\x80\\x93 was also shot in the leg; he has since been released from the hospital. Years before the shooting, however, Moreno\\xe2\\x80\\x99s social media posts have revealed that she once sent money to the megachurch where she then chose to carry out her attack, CNN reported. Genesse Moreno in mug shot   ( Supplied ) In March 2020, she posted a screenshot of a letter from  Lakewood Church  thanking her for her donation. Moreno\\xe2\\x80\\x99s social media accounts have since been taken down.  The Independent  has reached out to the Houston Police Department for more information but has not been able to independently verify the post or the donation. The motive of the shooting remains unclear, but Houston Police Department Commander Christopher Hassig said that Moreno penned \\xe2\\x80\\x9c antisemitic writings \\xe2\\x80\\x9d prior to the shooting and was in the middle of a familial dispute with her ex-husband, whose family is Jewish. \\xe2\\x80\\x9cWe think this is where this stems from,\\xe2\\x80\\x9d he said. The AR-15 used in the attack also had a sticker reading \\xe2\\x80\\x9cPalestine\\xe2\\x80\\x9d on it, police said. Police said that Moreno had a \\xe2\\x80\\x9cdocumented mental health history\\xe2\\x80\\x9d \\xe2\\x80\\x93 something that has been echoed by her ex-husband\\xe2\\x80\\x99s family and divorce records. A woman who identified herself on Facebook as Moreno\\xe2\\x80\\x99s former mother-in-law said that Moreno \\xe2\\x80\\x9cwas taking medication for schizophrenia\\xe2\\x80\\x9d. Divorce records from Montgomery County, obtained  by Fox26,  state that Moreno was diagnosed as \\xe2\\x80\\x9cschizophrenic\\xe2\\x80\\x9d and had a \\xe2\\x80\\x9chistory of erratic paranoid, stalking behaviour and was diagnosed as exhibiting Munchausen by proxy\\xe2\\x80\\x9d. She once stored a loaded gun in her then-three-year-old son\\xe2\\x80\\x99s diaper bag, the records state. Police also said that Moreno went by several \\xe2\\x80\\x9caliases\\xe2\\x80\\x9d including some male names.  Criminal records also identify her as Jeffery Escalante \\xe2\\x80\\x94 with the middle name Genesse. Despite the male name, authorities said, through \\xe2\\x80\\x9call the investigation to this point, she has been identified the entire time as female\\xe2\\x80\\x9d. Thr criminal records, seen by  The Independent , show Moreno had an expansive criminal history spanning from 2005 to 2022, including arrests including for assault, marijuana possession, forgery, theft, and unlawful carrying of a weapon. With the exception of the arrest pertaining to her alleged unlawful carrying of a weapon in 2022, all of the arrests are under the name Jeffery Escalante.\"}]}'\n",
      "{'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1750636800000'}, 'provider_name': None}}, 'user_id': 'user_2ysbUVxgqgRyKZF5uPpWKGS2brQ'}\n",
      "b'{\"model\": \"deepseek/deepseek-r1-0528:free\", \"messages\": [{\"role\": \"user\", \"content\": \"You are a news classification assistant.\\\\n\\\\nClassify into ONE category:\\\\n1. Conflict-related  \\xe2\\x80\\x93 News directly reporting on Israel\\xe2\\x80\\x93Palestine conflict events\\\\n2. Political Statements  \\xe2\\x80\\x93 Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\\\n3. Protests and Public Reactions  \\xe2\\x80\\x93 Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\\\n4. Irrelevant  \\xe2\\x80\\x93 Not related to the conflict in any way\\\\n\\\\nReturn ONLY the category name.\\\\n\\\\nTitle: US House still has no Speaker. Here\\'s what happens next\\\\n\\\\nContent: Jim Jordan\\'s quest for the speakership of the House has been off to a rough start While the pick of the majority of House Republicans projected confidence at the beginning of this week, two rounds of balloting have exposed significant resistance to his bid for the gavel. On Tuesday, 20 of his fellow Republicans opted to support someone else. That number grew to 22 with a second vote on Wednesday, plunging his leadership bid into disarray. The Trump-backed congressman had chosen to hold these public votes as part of a strategy to flush out opposition. He hoped to expose the nay votes as just a handful of holdouts and put them on the record, where they would wilt under the spotlight. Instead, the strategy revealed the strength and determination of his opposition. Despite reporting that they have received death threats and faced other less severe means of pressure, Mr Jordan\\'s Republican critics say they are united and undeterred. It sets up a standoff where, at some point, one side will have to give way. So what happens next? The Ohio congressman could continue to press for more Speaker votes. He has Mr Trump and much of the right-wing media ecosystem on his side, and can make life very uncomfortable for Republican politicians who are viewed as insufficiently loyal to the conservative cause. House in disarray as resistance hardens to Jordan Who is Speaker nominee Jim Jordan?  Threats fly as Jim Jordan\\'s bid to be US House Speaker turns ugly Unlike Mr McCarthy, who in January faced an ideologically cohesive group of right-wing conservatives with specific, although difficult to satisfy, demands, Mr Jordan confronts a somewhat disparate group of opponents.  There\\'s a knot of legislators from narrowly won districts in New York who may be fearful that Mr Jordan\\'s brand of confrontational politics will damage their re-election chances. Another group includes key members of the House Appropriations Committee, including its chairwoman, Kay Granger. They might be worried about Mr Jordan\\'s penchant for budget showdowns and resulting government shutdowns undermining their carefully negotiated and constructed government-funding legislation. The rest are an ideological hodgepodge from across the country, whose opposition ranges from tepid to vehement. Mr Jordan and his team will have to try to find ways to cajole or coerce his opponents into yielding while not doing so in a way that alienates his current crop of supporters. It will be no easy task.  Twenty votes is more than Kevin McCarthy, the recently ousted speaker, lost in his first ballot in January, during a process that stretched over several days and through 15 rounds of votes. It seems unlikely that Mr Jordan\\'s fellow Republicans will give him that much time to secure the Speaker\\'s gavel, given the current national and global circumstances. Mr Jordan can only afford to lose four Republican votes.  At some point, if Mr Jordan cannot demonstrate he is making progress towards winning the Speaker vote, Republicans are going to have to start looking for other options. Some have already floated giving Mr McCarthy, who was only narrowly unseated two weeks ago, another chance at the gavel. Since his ouster, no Republican candidate has matched his level of support among House Republicans. Another option being floated is to expand the powers of acting Speaker Patrick McHenry, allowing him to preside over urgent legislative matters, like approving aid to Israel after the Hamas attack. A majority of the House would probably have to approve this step, but some Democrats could go along if the scope of Mr McHenry\\'s powers are clearly defined. They might demand concessions in exchange for their support, as well. Some centrist Republicans have also broached the possibility of working with Democrats to form a coalition that can elect a centrist compromise Speaker. Democratic leader Hakeem Jeffries has been open to such an effort, although he says that such a move will have to allow Democrats to advance some of their own legislative priorities. Otherwise, Republicans are left hoping that a new candidate can emerge who will pull their party together and willingly accept what Republican congressman Ken Buck of Colorado recently described as the \\\\\"worst job in America\\\\\".\"}]}'\n",
      "{'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1750636800000'}, 'provider_name': None}}, 'user_id': 'user_2ysbUVxgqgRyKZF5uPpWKGS2brQ'}\n",
      "b'{\"model\": \"deepseek/deepseek-r1-0528:free\", \"messages\": [{\"role\": \"user\", \"content\": \"You are a news classification assistant.\\\\n\\\\nClassify into ONE category:\\\\n1. Conflict-related  \\xe2\\x80\\x93 News directly reporting on Israel\\xe2\\x80\\x93Palestine conflict events\\\\n2. Political Statements  \\xe2\\x80\\x93 Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\\\n3. Protests and Public Reactions  \\xe2\\x80\\x93 Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\\\n4. Irrelevant  \\xe2\\x80\\x93 Not related to the conflict in any way\\\\n\\\\nReturn ONLY the category name.\\\\n\\\\nTitle: Energy bills predicted to fall in April to \\xc2\\xa31,660\\\\n\\\\nContent: Annual energy bills for a typical household are expected to fall by \\xc2\\xa3268 in April, a new forecast suggests. Consultancy firm Cornwall Insight says bills could drop to \\xc2\\xa31,660 under the official price cap set by the UK\\'s energy regulator Ofgem. The energy price cap limits how much suppliers can charge households for each unit of energy they use. Analysts at Cornwall said a significant decline in wholesale energy prices would lead to the drop in April. The predicted fall comes as millions are set to see bills rise in January when the next price cap comes into force. Energy regulator Ofgem said the typical dual-fuel annual household bill would go up from \\xc2\\xa31,834 to \\xc2\\xa31,928 in January, a rise of \\xc2\\xa394. In its latest forecast, Cornwall said it expected bills to continue to fall throughout the year, falling to \\xc2\\xa31,590 in July before a slight increase to \\xc2\\xa31,640 from October. It said the Israel-Hamas conflict, strikes at a liquified natural gas plant in Australia and disruption at a gas pipeline in Finland had so far \\\\\"failed to materially impact energy supplies\\\\\". These factors, coupled with a relatively mild winter to date, have left European gas storage levels above expectations for the remainder of winter, helping to drive down wholesale prices, Cornwall analysts said. Dr Craig Lowrey, principal consultant at the group, said the dip \\\\\"may offer a small light at the end of the tunnel\\\\\".  \\\\\"The recent stabilisation of international energy markets has trickled down to April\\'s price cap predictions, raising hopes that this downward path will continue throughout the remainder of 2024,\\\\\" he said.  Energy bills could rise to cover customers\\' debts Energy firms must help customers with unpaid bills Calls for targeted energy help for most vulnerable But reflecting on the \\\\\"highly volatile\\\\\" wholesale energy market and \\\\\"unexpected global events,\\\\\" Dr Lowrey said \\\\\"there are no guarantees the price cap will not rise again\\\\\". \\\\\"Ongoing consultations on potential changes to the price cap, including the standing charge and bad debt collection\\\\\" he said, could impact the overall price cap level too. \\\\\"Ultimately, waiting and hoping that we will avoid another global incident that sends energy prices climbing is not a sustainable strategy for government\\\\\". The energy watchdog, Ofgem, sets a maximum price that suppliers can charge customers per unit of gas and electricity. The regulator\\'s price cap affects 29 million households in England, Wales and Scotland. Rules are different in  Northern Ireland . Ofgem sets the maximum amount that suppliers can charge for each unit of gas and electricity but not the total bill, so if you use more, you will pay more. To shield people in England, Wales and Scotland from much higher bills last year, the government introduced a \\xc2\\xa3400 discount for each household, but that scheme has now finished. But new Ofgem rules which came in on 14 December, require companies to contact vulnerable customers if they miss two monthly or one quarterly payment and check to see if they are having financial problems with their bills. Energy firms must help by offering affordable payment plans or repayment holidays if appropriate. It comes as households face paying extra on energy bills to cover customers\\' bad debts under plans by the industry regulator. Ofgem has proposed lifting the energy price cap by \\xc2\\xa316 between April next year and March 2025. It estimates that debt levels for energy customers has risen to \\xc2\\xa32.9bn.\"}]}'\n",
      "{'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1750636800000'}, 'provider_name': None}}, 'user_id': 'user_2ysbUVxgqgRyKZF5uPpWKGS2brQ'}\n",
      "b'{\"model\": \"deepseek/deepseek-r1-0528:free\", \"messages\": [{\"role\": \"user\", \"content\": \"You are a news classification assistant.\\\\n\\\\nClassify into ONE category:\\\\n1. Conflict-related  \\xe2\\x80\\x93 News directly reporting on Israel\\xe2\\x80\\x93Palestine conflict events\\\\n2. Political Statements  \\xe2\\x80\\x93 Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\\\n3. Protests and Public Reactions  \\xe2\\x80\\x93 Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\\\n4. Irrelevant  \\xe2\\x80\\x93 Not related to the conflict in any way\\\\n\\\\nReturn ONLY the category name.\\\\n\\\\nTitle: The New Hampshire-Canada border is small, but patrols are about to increase in a big way\\\\n\\\\nContent: CONCORD, N.H. (AP) \\xe2\\x80\\x94 New Hampshire announced a tenfold increase in patrols along the Canadian border Thursday, with Republican leaders promising to use state and local law enforcement to close what they consider a potentially dangerous gap in public safety. \\xe2\\x80\\x9cThere\\xe2\\x80\\x99s national security implications to securing the northern border that are becoming more and more obvious every day,\\xe2\\x80\\x9d Gov. Chris Sununu said at a news conference. \\xe2\\x80\\x9cIn light of the terrorist attacks by  Hamas  aimed at innocent Israelis, global tensions and threats are now at an all-time high.\\xe2\\x80\\x9d Along with Attorney General John Formella, Sununu outlined how the state will use $1.4 million included in the current state budget to create the Northern Border Alliance Task Force. Formella said the partnership between state, county and local law enforcement will increase border patrol hours from roughly 55 per month to a total of 10,000 hours in the next 18 months. \\\\n     \\\\n\\\\n Statistics from U.S. Customs and Border Protection show that agents in the 295-mile (475-kilometer) sector that includes New Hampshire, Vermont and parts of upstate New York apprehended 5,970 illegal border crossers between Oct. 1, 2022, through Aug. 31, 2023, up from 829 in the same period the year before. The total number apprehended along the entire northern border during that time, 170,565, is a small fraction of those apprehended along the  U.S.-Mexican border  during that same period, 2.1 million. \\\\n\\\\n \\\\n     \\\\n        \\\\n \\\\n    \\\\n\\\\n    \\\\n     \\\\n\\\\n\\\\n\\\\n\\\\n     \\\\n        \\\\n        \\\\n        \\\\n             \\\\n                 \\\\n                    RELATED COVERAGE\\\\n                 \\\\n             \\\\n        \\\\n        \\\\n        \\\\n        \\\\n     \\\\n\\\\n\\\\n     \\\\n            \\\\n        \\\\n             \\\\n                \\\\n                    \\\\n                         \\\\n   \\\\n    \\\\n        \\\\n            \\\\n     \\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n \\\\n \\\\n \\\\n\\\\n\\\\n        \\\\n    \\\\n\\\\n     \\\\n        \\\\n        \\\\n        \\\\n\\\\n        \\\\n    \\\\n         \\\\n             \\\\n                 Canada\\xe2\\x80\\x99s Liberal Party to decide on March 9 who will succeed Trudeau as prime minister \\\\n             \\\\n         \\\\n    \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n    \\\\n    \\\\n    \\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n        \\\\n\\\\n        \\\\n\\\\n        \\\\n     \\\\n\\\\n    \\\\n \\\\n                    \\\\n                 \\\\n        \\\\n             \\\\n                \\\\n                    \\\\n                         \\\\n   \\\\n    \\\\n        \\\\n            \\\\n     \\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n \\\\n \\\\n \\\\n\\\\n\\\\n        \\\\n    \\\\n\\\\n     \\\\n        \\\\n        \\\\n        \\\\n\\\\n        \\\\n    \\\\n         \\\\n             \\\\n                 Indiana man who fled to avoid prison sentence for storming Capitol is arrested in Canada \\\\n             \\\\n         \\\\n    \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n    \\\\n    \\\\n    \\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n        \\\\n\\\\n        \\\\n\\\\n        \\\\n     \\\\n\\\\n    \\\\n \\\\n                    \\\\n                 \\\\n        \\\\n             \\\\n                \\\\n                    \\\\n                         \\\\n   \\\\n    \\\\n        \\\\n            \\\\n     \\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n\\\\n    \\\\n         \\\\n\\\\n    \\\\n \\\\n \\\\n \\\\n\\\\n\\\\n        \\\\n    \\\\n\\\\n     \\\\n        \\\\n        \\\\n        \\\\n\\\\n        \\\\n    \\\\n         \\\\n             \\\\n                 US orange juice and steel will be on Canada\\xe2\\x80\\x99s list for retaliation if Trump imposes tariffs \\\\n             \\\\n         \\\\n    \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n\\\\n\\\\n        \\\\n    \\\\n    \\\\n    \\\\n\\\\n\\\\n\\\\n        \\\\n\\\\n\\\\n        \\\\n\\\\n        \\\\n\\\\n        \\\\n     \\\\n\\\\n    \\\\n \\\\n                    \\\\n                 \\\\n        \\\\n     \\\\n    \\\\n\\\\n \\\\n\\\\n\\\\n\\\\n     \\\\n \\\\n\\\\n New Hampshire borders Canada for less than 60 miles (97 kilometers), and it\\xe2\\x80\\x99s unclear how many illegal crossings happen there. Sununu said action is needed given that encounters with people on the terrorist watch list along the northern border as a whole have increased. \\\\n    \\\\n     \\\\n         \\\\n             \\\\n                 \\\\n    \\\\n     \\\\n\\\\n\\\\n     \\\\n     \\\\n        \\\\n     \\\\n \\\\n             \\\\n         \\\\n     \\\\n    \\\\n \\xe2\\x80\\x9cWe can\\xe2\\x80\\x99t stand by, and we won\\xe2\\x80\\x99t,\\xe2\\x80\\x9d Sununu said. \\xe2\\x80\\x9cWe\\xe2\\x80\\x99re going to do whatever we can to make sure that we\\xe2\\x80\\x99re providing the necessary resources and security for our citizens.\\xe2\\x80\\x9d \\\\n     \\\\n\\\\n Last spring, when lawmakers were debating the budget provision, the American Civil Liberties Union of New Hampshire filed a lawsuit seeking release of state-specific data about border crossings. Frank Knaack, the organization\\xe2\\x80\\x99s policy director, said Thursday the $1.4 million would be better invested in housing, broadband and substance use treatment than expanding police power and surveillance under the guise of a border crisis. \\xe2\\x80\\x9cPolicies like this have been shown in study after study to further undermine police and community trust, which makes our communities less safe,\\xe2\\x80\\x9d he said. \\xe2\\x80\\x9cMake no mistake: we\\xe2\\x80\\x99ll be watching the actions of law enforcement, including how every dollar is spent, very closely.\\xe2\\x80\\x9d Formella said he would provide as much transparency as possible without compromising investigations. The task force, which will include state police, forest rangers, Fish and Game officers and county and local law enforcement, will patrol within 25 miles (40 kilometers) of the border. Members will cooperate with federal officers to enforce federal immigration laws. Most of New Hampshire\\xe2\\x80\\x99s border with Canada is in the town of Pittsburg, where Police Chief Rick Dube said there have been issues, though he declined to describe specific instances. \\xe2\\x80\\x9cIt\\xe2\\x80\\x99s a cat-and-mouse game. You got to be in the right spot at the right time. They could be in the woods, and it\\xe2\\x80\\x99s so dense up there, they can be 5 feet away from you, 10 feet away from you and you can walk right by them,\\xe2\\x80\\x9d he said. \\xe2\\x80\\x9cIt\\xe2\\x80\\x99s a struggle.\\xe2\\x80\\x9d\"}]}'\n",
      "{'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1750636800000'}, 'provider_name': None}}, 'user_id': 'user_2ysbUVxgqgRyKZF5uPpWKGS2brQ'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(art[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     64\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(classify_one(art))\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# keep under rate limits\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Print metrics\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Counter(y_pred))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Load the same data\n",
    "with open(\"articles_test.json\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "# We’ll do just the first 20\n",
    "articles20 = articles[:20]\n",
    "\n",
    "# Your OpenRouter key here\n",
    "API_KEY = \"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\"\n",
    "URL     = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Label mapping\n",
    "label_map = {\n",
    "    \"Conflict-related\":              1,\n",
    "    \"Protests and Public Reactions\": 2,\n",
    "    \"Political Statements\":          3,\n",
    "    \"Irrelevant\":                    4\n",
    "}\n",
    "reverse_map = {v:k for k,v in label_map.items()}\n",
    "\n",
    "def classify_one(article):\n",
    "    # Build the prompt\n",
    "    prompt = (\n",
    "        \"You are a news classification assistant.\\n\\n\"\n",
    "        \"Classify into ONE category:\\n\"\n",
    "        \"1. Conflict-related  – News directly reporting on Israel–Palestine conflict events\\n\"\n",
    "        \"2. Political Statements  – Statements by world leaders on the conflict - Only inlcude if the article reports on political statement made directly relating to the israel hamas conflict\\n\"\n",
    "        \"3. Protests and Public Reactions  – Citizen protests or opinion pieces on the israel and hamas conflict or the larger war\\n\"\n",
    "        \"4. Irrelevant  – Not related to the conflict in any way\\n\\n\"\n",
    "        \"Return ONLY the category name.\\n\\n\"\n",
    "        f\"Title: {article['title']}\\n\\n\"\n",
    "        f\"Content: {article['text']}\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\":    \"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "        \"messages\": [{\"role\":\"user\",\"content\":prompt}]\n",
    "    }\n",
    "    # Encode JSON as UTF-8 to avoid Latin-1 issues\n",
    "    body = json.dumps(payload, ensure_ascii=False).encode(\"utf-8\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json; charset=utf-8\"\n",
    "    }\n",
    "    print(body)\n",
    "    r = requests.post(URL, headers=headers, data=body)\n",
    "    if r.status_code != 200:\n",
    "        print(r.json())\n",
    "        return 4\n",
    "    reply = r.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
    "    for cat, idx in label_map.items():\n",
    "        if cat.lower() in reply:\n",
    "            return idx\n",
    "    print(r.json())\n",
    "    return 4\n",
    "\n",
    "# Run classification\n",
    "y_true, y_pred = [], []\n",
    "for art in articles20:\n",
    "    y_true.append(art[\"label\"])\n",
    "    y_pred.append(classify_one(art))\n",
    "    time.sleep(1.2)  # keep under rate limits\n",
    "\n",
    "# Print metrics\n",
    "print(\"Counts:\", Counter(y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=[1,2,3,4],\n",
    "    target_names=list(label_map.keys())\n",
    "))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "# Print mismatches\n",
    "print(\"\\nMISMATCHED ARTICLES:\")\n",
    "for art, t, p in zip(articles20, y_true, y_pred):\n",
    "    if t != p:\n",
    "        print(f\"- Title: {art['title']}\")\n",
    "        print(f\"  URL:   {art.get('url','N/A')}\")\n",
    "        print(f\"  True:  {reverse_map[t]}\")\n",
    "        print(f\"  Pred:  {reverse_map[p]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b8b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISMATCHED ARTICLES:\n",
      "- Title: Ramadan in Gaza: Palestinians fast amid war, devastation and looming famine\n",
      "  URL:   https://www.nbcnews.com/news/world/ramadan-gaza-palestinians-israel-war-famine-rcna142785\n",
      "  True:  Conflict-related\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: UCLA anti-Israel protesters took hand-to-hand combat classes ahead of bloody clash\n",
      "  URL:   https://nypost.com/2024/05/01/us-news/ucla-anti-israel-protesters-took-hand-to-hand-classes-ahead-of-bloody-clash/\n",
      "  True:  Protests and Public Reactions\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: Newspaper headlines: Conflicting Gaza death accounts and police vetting failures\n",
      "  URL:   https://www.bbc.com/news/blogs-the-papers-68443012\n",
      "  True:  Protests and Public Reactions\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: Republicans blast Biden over plans to take in Gaza refugees: ‘Absolute disgrace’\n",
      "  URL:   https://nypost.com/2024/05/01/us-news/republicans-blast-biden-over-plans-to-take-in-gaza-refugees-absolute-disgrace/\n",
      "  True:  Political Statements\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: Yousaf hits out at Cleverly over omission in UK policy on Israel-Hamas conflict\n",
      "  URL:   https://www.independent.co.uk/news/uk/humza-yousaf-gaza-hamas-first-minister-israel-b2432679.html\n",
      "  True:  Political Statements\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: How Lebanon’s Hezbollah group became a critical player in the Israel-Hamas war\n",
      "  URL:   https://apnews.com/article/hezbollah-israel-hamas-war-lebanon-iran-493e9290bc796fd90a9220bab229cd37\n",
      "  True:  Conflict-related\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: Palestinian militants kill 2 alleged informers for Israel and mob drags bodies through camp alleys\n",
      "  URL:   https://apnews.com/article/palestinians-collaborators-israel-west-bank-8da4d4b0dbbd0c2daa7abacde19a0b5d\n",
      "  True:  Conflict-related\n",
      "  Pred:  Irrelevant\n",
      "\n",
      "- Title: US military to build floating pier to ferry Gaza aid, White House says\n",
      "  URL:   https://indianexpress.com/article/world/us-military-build-floating-pier-ferry-gaza-aid-white-house-says-9202286/\n",
      "  True:  Political Statements\n",
      "  Pred:  Irrelevant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print mismatches\n",
    "print(\"\\nMISMATCHED ARTICLES:\")\n",
    "for art, t, p in zip(articles20, y_true, y_pred):\n",
    "    if t != p:\n",
    "        print(f\"- Title: {art['title']}\")\n",
    "        print(f\"  URL:   {art.get('url','N/A')}\")\n",
    "        print(f\"  True:  {reverse_map[t]}\")\n",
    "        print(f\"  Pred:  {reverse_map[p]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b71f0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status: 200\n",
      "Response Body:\n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "\n",
      "         \n",
      "{\"id\":\"gen-1750634484-YYETfxaDDtDLp6JkFF2s\",\"provider\":\"Chutes\",\"model\":\"mistralai/mistral-small-3.2-24b-instruct:free\",\"object\":\"chat.completion\",\"created\":1750634484,\"choices\":[{\"logprobs\":null,\"finish_reason\":\"stop\",\"native_finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Conflict-related\",\"refusal\":null,\"reasoning\":null}}],\"usage\":{\"prompt_tokens\":537,\"completion_tokens\":3,\"total_tokens\":540}}\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "\n",
    "API_KEY = \"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\"\n",
    "URL     = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Build your payload\n",
    "prompt = (\n",
    "    \"You are a news classification assistant.\\n\\n\"\n",
    "    \"Classify into ONE category:\\n\"\n",
    "    \"1. Conflict-related  - News directly reporting on Israel–Palestine events\\n\"\n",
    "    \"2. Political Statements  - Statements by world leaders on the conflict\\n\"\n",
    "    \"3. Protests and Public Reactions  - Citizen protests or opinion pieces\\n\"\n",
    "    \"4. Irrelevant  - Not related\\n\\n\"\n",
    "    \"Return ONLY the category name.\\n\\n\"\n",
    "    \"Title: Newspaper headlines: Conflicting Gaza death accounts and police vetting failures\"\n",
    "    \"Content: The dramatic political comeback of George Galloway presents Sir Keir Starmer with another headache -  according to the Sun ,  external  in its online coverage.   The paper says the left-wing firebrand and former Big Brother contestant focused on Gaza as he gallivanted through mosques across Rochdale, to seize the support of its Muslim population.   The Times says ,  external  the campaign was one of the most divisive in recent years.   The Guardian uses ,  external  the same word to describe Mr Galloway.  It says he was so confident of victory that shortly after the polls closed, he\\'d briefed reporters that he\\'d won comfortably, before announcing plans for a mass rally.  The Daily Telegraph covers the spat ,  external  between Rochdale\\'s new MP and the leader of the Reform Party, Richard Tice - who claims that his candidate and campaigners suffered abuse and death threats.  Mr Galloway rejects the suggestion his supporters engaged in bad behaviour - saying that Mr Tice had \\\\rather lost his balance\\\\.   The front page picture of  the Guardian captures  ,  external the aftermath of the chaos in Gaza.  It shows three Palestinian men holding a body, which is wrapped in a white sheet.  The paper says there are \\\\starkly different accounts\\\\ of how the deaths occurred.   The Times believes ,  external  the tragedy will almost certainly end hopes of a six week ceasefire.  In an analysis piece, it says Israel is dependent on the Biden administration for arms and diplomatic support - and the moment where America pushes the brakes seems near. There\\'s widespread condemnation of the errors made by the Metropolitan Police, which led to the appointment of Wayne Couzens to the Diplomatic Protection Squad -- before he kidnapped and murdered the marketing executive, Sarah Everard.  Sarah Vine  in the Daily Mail says ,  external  it would have been hard-wired into Ms Everard\\'s brain that a policeman was someone she could trust and that it sets her blood boiling, that she met a monster.   The Sun is equally condemnatory ,  external  describing officers responsible for vetting recruits a\"\n",
    ")\n",
    "\n",
    "payload = {\n",
    "    \"model\":    \"mistralai/mistral-small-3.2-24b-instruct:free\",     # or try \"deepseek-r1\" if that errors\n",
    "    \"messages\": [{\"role\":\"user\",\"content\":prompt}]\n",
    "}\n",
    "\n",
    "# Prepare request\n",
    "body = json.dumps(payload, ensure_ascii=False).encode(\"utf-8\")\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\":  \"application/json; charset=utf-8\"\n",
    "}\n",
    "\n",
    "# Send & debug\n",
    "resp = requests.post(URL, headers=headers, data=body)\n",
    "print(\"HTTP Status:\", resp.status_code)\n",
    "print(\"Response Body:\")\n",
    "print(resp.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8faff3",
   "metadata": {},
   "source": [
    "## Cerebras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a38ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction counts: Counter({1: 10, 4: 6, 2: 3, 3: 1})\n",
      "\n",
      "Classification Report:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "             Conflict-related       0.30      1.00      0.46         3\n",
      "Protests and Public Reactions       0.33      0.50      0.40         2\n",
      "         Political Statements       1.00      0.33      0.50         3\n",
      "                   Irrelevant       1.00      0.50      0.67        12\n",
      "\n",
      "                     accuracy                           0.55        20\n",
      "                    macro avg       0.66      0.58      0.51        20\n",
      "                 weighted avg       0.83      0.55      0.58        20\n",
      "\n",
      "Macro F1: 0.507051282051282\n",
      "\n",
      "MISMATCHED ARTICLES:\n",
      "- Title: Lakewood shooter ‘donated money to megachurch’ before attack that left son fighting for life\n",
      "  URL:   https://www.independent.co.uk/news/world/americas/crime/lakewood-shooter-donated-megachurch-letter-b2495530.html\n",
      "  True:  Irrelevant\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: The New Hampshire-Canada border is small, but patrols are about to increase in a big way\n",
      "  URL:   https://apnews.com/article/new-hampshire-northern-border-security-5b11643a667f1fabce852be5367b0ea1\n",
      "  True:  Irrelevant\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: Builder, 36, has gone into hiding after receiving torrent of abusive messages from people wrongly mistaking him as in Waterloo Station 'racist' video\n",
      "  URL:   https://www.dailymail.co.uk/news/article-12752501/builder-nightmare-mistakenly-identified-london-waterloo-racist-video.html\n",
      "  True:  Irrelevant\n",
      "  Pred:  Protests and Public Reactions\n",
      "\n",
      "- Title: Newspaper headlines: Conflicting Gaza death accounts and police vetting failures\n",
      "  URL:   https://www.bbc.com/news/blogs-the-papers-68443012\n",
      "  True:  Protests and Public Reactions\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: Republicans blast Biden over plans to take in Gaza refugees: ‘Absolute disgrace’\n",
      "  URL:   https://nypost.com/2024/05/01/us-news/republicans-blast-biden-over-plans-to-take-in-gaza-refugees-absolute-disgrace/\n",
      "  True:  Political Statements\n",
      "  Pred:  Protests and Public Reactions\n",
      "\n",
      "- Title: What the papers say – March 1\n",
      "  URL:   https://www.independent.co.uk/news/uk/russia-christian-horner-daily-express-vladimir-putin-ukraine-b2505167.html\n",
      "  True:  Irrelevant\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: Israeli missile strike in Syria kills several Iran Revolutionary Guard members, including information head\n",
      "  URL:   https://nypost.com/2024/01/20/news/israel-strikes-kill-at-least-four-in-syria-lebanon/\n",
      "  True:  Irrelevant\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: US military to build floating pier to ferry Gaza aid, White House says\n",
      "  URL:   https://indianexpress.com/article/world/us-military-build-floating-pier-ferry-gaza-aid-white-house-says-9202286/\n",
      "  True:  Political Statements\n",
      "  Pred:  Conflict-related\n",
      "\n",
      "- Title: UPSC Key | Israel-Hezbollah conflict, Data protection law, Passive euthanasia and more\n",
      "  URL:   https://indianexpress.com/article/upsc-current-affairs/upsc-key-israel-hezbollah-conflict-data-protection-law-passive-euthanasia-9594621/\n",
      "  True:  Irrelevant\n",
      "  Pred:  Conflict-related\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "# 1) Ensure your API key is set:\n",
    "#    export CEREBRAS_API_KEY=\"your_real_key_here\"\n",
    "client = Cerebras(api_key=\"csk-3vy3dm6wyff5xpc8mjfy32498ew8cc5h4fw9cjxxyh3j5r95\")\n",
    "\n",
    "# 2) Load the first 20 articles\n",
    "with open(\"articles_test.json\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "articles20 = articles[:20]\n",
    "\n",
    "# 3) Define your label mappings\n",
    "label_map = {\n",
    "    \"Conflict-related\":              1,\n",
    "    \"Protests and Public Reactions\": 2,\n",
    "    \"Political Statements\":          3,\n",
    "    \"Irrelevant\":                    4\n",
    "}\n",
    "reverse_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# 4) Classification function via Cerebras\n",
    "def classify_one(article):\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a precise news classification assistant. \"\n",
    "            \"Respond with exactly one of: Conflict-related, Political Statements, \"\n",
    "            \"Protests and Public Reactions, Irrelevant.\"\n",
    "        )\n",
    "    }\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Classify into ONE category:\\n\"\n",
    "            \"1. Conflict-related – News directly reporting on Israel–Palestine conflict events\\n\"\n",
    "            \"2. Political Statements – Statements by world leaders on the conflict\\n\"\n",
    "            \"3. Protests and Public Reactions – Citizen protests or opinion pieces on the conflict\\n\"\n",
    "            \"4. Irrelevant – Not related to the conflict\\n\\n\"\n",
    "            f\"Title: {article['title']}\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "# f\"Content: {article['text']}\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama-4-scout-17b-16e-instruct\",\n",
    "        messages=[system_msg, user_msg],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    reply = resp.choices[0].message.content.strip().lower()\n",
    "    for cat, idx in label_map.items():\n",
    "        if cat.lower() in reply:\n",
    "            return idx\n",
    "    return label_map[\"Irrelevant\"]  # fallback\n",
    "\n",
    "# 5) Run classification and collect results\n",
    "y_true, y_pred = [], []\n",
    "for art in articles20:\n",
    "    y_true.append(art[\"label\"])\n",
    "    y_pred.append(classify_one(art))\n",
    "    time.sleep(1.2)  # rate-limit\n",
    "\n",
    "# 6) Print evaluation\n",
    "print(\"Prediction counts:\", Counter(y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=[1,2,3,4],\n",
    "    target_names=list(label_map.keys())\n",
    "))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "# 7) List mismatches\n",
    "print(\"\\nMISMATCHED ARTICLES:\")\n",
    "for art, t, p in zip(articles20, y_true, y_pred):\n",
    "    if t != p:\n",
    "        print(f\"- Title: {art['title']}\")\n",
    "        print(f\"  URL:   {art.get('url','N/A')}\")\n",
    "        print(f\"  True:  {reverse_map[t]}\")\n",
    "        print(f\"  Pred:  {reverse_map[p]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
